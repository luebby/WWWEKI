---
title: "Modul 04: Es steht was zwischen uns"
output: 
  learnr::tutorial:
    language: 
      de: js/tutorial_de.json
    progressive: true
    css: "css/style.css"
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(knitr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(emojifont)

theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)

# deutsche Version von random_praise
source("random-praise_de/translation_random-praise_de.R")


library(ggdag)
# DAG
co <- data.frame(x=c(0,1,2), y=c(0,0,0), name=c("X", "Z", "Y"))
DAG_Chain <- dagify(Z ~ X,
                    Y ~ Z,
                   coords = co) %>% 
  ggdag() + 
  geom_dag_point(colour = c("#0F710B", "#DA70D6", "#0000FF")) + 
  geom_dag_text(size = 8) +
  theme_dag_blank() +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(15, "pt"), type = "closed")) +
  geom_text(label = "X - Lernen\nZ - Wissen\nY - Verstehen", 
            hjust = 1, vjust = 2,
            x = 2, y = 0, size = 7, color = "darkgrey") 


library(mosaic)

U_X <- function(n = 1) runif(n, min = 1, max = 10)
f_Z <- function(x) 5*x + rnorm(length(x))
f_Y <- function(z) 3*z + rnorm(length(z))

# Daten und Funktion
set.seed(1992)
n <- 100
SimData <- tibble(x = U_X(n)) %>%
  mutate(z = f_Z(x)) %>%
  mutate(y = f_Y(z))

# Ergebnisse
ModellA <- lm(y ~ x, data = SimData)
```

## Lernziele

In diesem Modul lernen Sie:

- was eine kausale Kette ist;

- was ein Mediator ist;

- dass es manchmal besser ist, bestimmte Variablen in der Analyse nicht zu berücksichtigen.

## Eins führt zum anderen

Auch komplexe kausale Diagramme bestehen aus relativ einfachen Grundelementen. Eines davon ist die sog. **Kette** (engl.: chain). 

Zur Erinnerung: Der kausale Fluss folgt den Pfeilen. $$A \rightarrow B$$ sagt aus, dass $B$ auf $A$ *hört*. Im Modul zwei: Wenn es regenet, ($A$), wird die Straße nass ($B$). 

Bei einer Kette kommt einfach eine dritte Variable dazu: $$A \rightarrow B \rightarrow C.$$ 
Zum Beispiel: wenn es regenet, ($A$) wird die Straße nass ($B$) und es wird rutschig ($C$).


## Lernen und Verstehen

Das folgende Beispiel ist fiktiv &ndash; und eine sehr starke Vereinfachung. Außerdem wird die wichtige Frage, wie die Variablen jeweils gemessen werden, nicht behandelt.

***

*Anmerkung*: Siehe hierzu z. B. "Welche Information steckt in Daten?" aus dem KI-Campus Kurs [Stadt | Land | DatenFluss](https://ki-campus.org/datenfluss).

***

Angenommen, <green>Lernen</green> ($\color{green}{X}$) führt zu <violet>Wissen</violet> ($\color{violet}{Z}$), d. h., durch Lernen erwerben Sie Wissen. Außerdem führt <violet>Wissen</violet> ($\color{violet}{Z}$) zu <blue>Verstehen</blue> ($\color{blue}{Y}$), d. h., über Ihr Wissen kommen Sie zum Verstehen.

Wenn dieses stark vereinfachte Modell stimmt, dann lässt sich diese Annahme in einem kausalen Diagramm darstellen:

```{r DAG_Chain, echo=FALSE, fig.align='center', out.width='85%'}
plot(DAG_Chain)
```

##

Das strukturelle kausale Modell besteht aus folgenden Zuweisungen:

\begin{eqnarray*}
\color{green}{X} &=& U_{\color{green}{X}}\\
\color{violet}{Z} &=& f_{\color{violet}{Z}}(\color{green}{X}, U_{\color{violet}{Z}})\\
\color{blue}{Y} &=& f_{\color{blue}{Y}}(\color{violet}{Z},U_{\color{blue}{Y}}).
\end{eqnarray*}

Der Wert von <green>Lernen</green> ($\color{green}{X}$) kommt außerhalb des Modells zu Stande ($U_{\color{green}{X}}$). Der Wert von <violet>Wissen</violet> ($\color{violet}{Z}$) hängt ab vom Wert von <green>Lernen</green> ($\color{green}{X}$) &ndash; und weiteren Faktoren ($U_{\color{violet}{Z}}$). Letzlich hängt <blue>Verstehen</blue> ($\color{blue}{Y}$) von <violet>Wissen</violet> ($\color{violet}{Z}$) ab &ndash; und $U_{\color{blue}{Y}}$. Hier machen wir wieder die (zugegebenermaßen unrealistische) Annahme, dass die zufälligen Einflüsse $U_{\color{green}{X}}, U_{\color{violet}{Z}}, U_{\color{blue}{Y}}$ voneinander unabhängig sind.

```{r kind, echo=FALSE}
question("In der Sprache der Diagramme: Ist Verstehen ($Y$) ein Kind von Lernen ($X$)?",
         answer("Ja"),
         answer("Nein", correct = TRUE, message = "Verstehen ist ein Kind von Wissen ($Z$). Wissen ist wiederum ein Kind von Lernen. Damit ist Verstehen kein Kind von Lernen, aber ein Nachkomme. Verstehen *hört* unmittelbar nur auf Wissen, d. h., der Wert von Verstehen hängt direkt nur von Wissen ab."),
         allow_retry = TRUE,
         correct = "Prima, Richtig!",
         incorrect = "Leider falsch. Vielleicht schauen Sie noch einmal im Modul 2 nach."
         )
```

## Mediator

In Fällen wie diesen: $$\color{green}{X} \rightarrow \color{violet}{Z} \rightarrow \color{blue}{Y}$$ wird die Variable in der Mitte &ndash; hier $\color{violet}{Z}$ &ndash; **Mediator** genannt.

```{r mediator, echo=FALSE}
question("Angenommen eine Beförderung hängt diskriminierenderweise ab vom Geschlecht der Kandidat:in und das Gehalt wiederum von der Beförderung. Welche Variable ist hier ein Mediator?",
         answer("Geschlecht"),
         answer("Beförderung", correct = TRUE, message = "Das beschriebene Kausalmodell lautet $\\text{Geschlecht} \\rightarrow \\text{Beförderung} \\rightarrow \\text{Gehalt}$."),
         answer("Gehalt", message = "Das beschriebene Kausalmodell lautet $\\text{Geschlecht} \\rightarrow \\text{Beförderung} \\rightarrow \\text{Gehalt}$."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

Um den kausalen Effekt der Ursache ($\color{green}{X}$) auf die Wirkung ($\color{blue}{Y}$) zu untersuchen, müssen wir den Wert des Mediators ($\color{violet}{Z}$) nicht kennen. Wenn wir also zum Beispiel wissen wollen, wie sich das <green>Geschlechts</green> insgesamt auf das <blue>Gehalt</blue> auswirkt, brauchen wir keine Informationen über <violet>Beförderungen</violet>.

Tatsächlich kann sogar die Berücksichtigung des Mediators dazu führen, dass der kausale Effekt verzerrt wird. Das werden wir im Folgenden mithilfe einer Simulation genauer betrachten. 

***

*Anmerkung*: Im Kontext von Mediation wird zwischen *totalen*, *direkten* und *indirekten* Effekte unterscheiden. Im Beispiel interessiert uns der gesamte Effekt von Geschlecht, der totale Effekt. 

Würde uns stattdessen interessieren, inwiefern Geschlecht unabhängig von Beförderung einen Effekt auf das Gehalt hat, so wäre das Analyseziel der direkte Effekt. Und wenn uns interessieren würde, inwiefern die Effekte des Geschlechts über Beförderungen vermittelt würden, so wäre das Analyseziel der indirekte Effekt.

***


## Simulierte Daten

Zurück zum Zusammenhang von Lernen, Wissen und Verstehen.
In `R` sind Simulationen für das Modell 

\begin{eqnarray*}
\color{green}{X} &=& U_{\color{green}{X}}\\
\color{violet}{Z} &=& f_{\color{violet}{Z}}(\color{green}{X}, U_{\color{violet}{Z}})\\
\color{blue}{Y} &=& f_{\color{blue}{Y}}(\color{violet}{Z},U_{\color{blue}{Y}}).
\end{eqnarray*}

hinterlegt. 

Zur Erinnerung (siehe auch Modul 2), $U$ bezeichnet jeweils unbekannte Ursachen; $f$ die Funktionen, anhand derer den Variablen Werte zugewiesen werden.

Simulieren Sie Beobachtungen in dem Sie mehrfach auf `Ausführen` klicken und versuchen Sie zu erkennen, wie die Variablen miteinander zusammenhängen:

```{r sim, exercise=TRUE}
x <- U_X()
cat("Wert x (Lernen):", x, "\n")
z <- f_Z(x)
cat("Wert z (Wissen):", z, "\n")
y <- f_Y(z)
cat("Wert y (Verstehen):", y, "\n")
```

```{r beobachtung, echo=FALSE}
question("Was passiert, wenn Sie höhere Werte von Lernen (`x`) beobachten?",
         answer("Bei höheren Werten von Lernen (`x`) treten in der Regel auch höhere Werte von Verstehen (`y`) auf.", correct = TRUE, message = "Es lässt sich ein positiver Zusammenhang zwischen $X$ und $Y$ beobachten."),
         answer("Bei höheren Werten von Lernen (`x`) treten in der Regel niedrigere Werte von Verstehen (`y`) auf."),
         answer("Der Wert von Verstehen (`y`) scheint in keinem Zusammenhang mit dem Wert von Lernen (`x`) zu stehen."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

## Intervention

Statt nur zu beobachten ($\color{green}{X} = U_{\color{green}{X}}$) können wir auch eine Intervention simulieren, in der wir Werte festlegen ($do(\color{green}{X}=x)$).

Im Code-Beispiel ist $do(\color{green}{X}=1)$. Drücken Sie zunächst ein paar Mal auf `Ausführen` um zu gucken, wie die Werte von Verstehen ($\color{blue}{Y}$) im Falls von $do(\color{green}{X}=1)$ aussehen. Ändern Sie anschließend den Code so, dass Sie $do(\color{green}{X}=10)$ simulieren können. Was passiert? 

```{r simdo, exercise=TRUE}
 # Hier der Befehl fuer do(X=1)
x <- 1
cat("Wert x (Lernen):", x, "\n")
z <- f_Z(x)
cat("Wert z (Wissen):", z, "\n")
y <- f_Y(z)
cat("Wert y (Verstehen):", y, "\n")
```

```{r simdo-solution}
 # do(X=10)
x <- 10
cat("Wert x (Lernen):", x, "\n")
z <- f_Z(x)
cat("Wert z (Wissen):", z, "\n")
y <- f_Y(z)
cat("Wert y (Verstehen):", y, "\n")
```

Für die Erläuterung bitte auf `Weiter` klicken.

##

Während die Werte für $\color{blue}{Y}$ bei $do(\color{green}{X}=1)$ um die $\color{blue}{15}$ schwanken, liegen sie bei $do(\color{green}{X}=10)$ um die $\color{blue}{150}$. Wir sehen also, dass eine Veränderung von $\color{green}{X}$ tatsächlich zu einer Veränderung von $\color{blue}{Y}$ führt. Dieser kausale Zusammenhang wird durch $\color{violet}{Wissen}$ vermittelt: Mehr Lernen führt zu mehr Wissen führt zu mehr Verstehen.


```{r intervention, echo=FALSE}
question("Überlegen Sie: Was wird passieren mit dem Zusammenhang zwischen Lernen (`x`) und Verstehen (`y`), wenn wir Wissen kennen, also z.B. `z <- 15`?",
         answer("Bei höheren Werten von Lernen (`x`) treten weiterhin in der Regel auch höhere Werte von Verstehen (`y`) auf.",),
         answer("Bei höheren Werten von Lernen (`x`) treten jetzt in der Regel niedrigere Werte von Verstehen (`y`) auf.",),
         answer("Bei festem Wissen (`z`) steht der Wert von Verstehen (`y`) in keinem Zusammenhang mit dem Wert von Lernen (`x`).", correct = TRUE, message = "Durch Kenntnis von `z` wird die kausale Kette von $X$ nach $Y$ unterbrochen. Wir hatten ja schon vorab gesagt, dass Verstehen nur direkt auf Wissen hört. Wenn sich Wissen nicht ändert, ändert sich hier also auch nicht das Verstehen. Das können Sie auch gleich noch mal in der Simulation testen."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

##

Probieren Sie dies durch Klick auf `Ausführen` ruhig aus:

```{r sim2, exercise=TRUE}
x <- U_X()
cat("Wert x (Lernen):", x, "\n")
z <- 15
cat("Wert z (Wissen):", z, "\n")
y <- f_Y(z)
cat("Wert y (Verstehen):", y, "\n")
```

Der bekannte Wert von `z` wird in Zeile 3 unabhängig vom Wert von `x` auf $15$ gesetzt.
Jetzt schwanken `x` und `y` zwar noch zufällig, sind aber unabhängig voneinander.

## Kausales Modell

Die zugrunde liegenden Gleichungen des soeben simulierten kausalen Modells lauten:

\begin{eqnarray*}
\color{green}{X} &=& U_{\color{green}{X}}, \quad U_{\color{green}{X}} \sim \mathcal{G}(1,\,10), \\
\color{violet}{Z} &=& 5 \cdot \color{green}{X} +  U_{\color{violet}{Z}}, \quad U_{\color{violet}{Z}} \sim \mathcal{N}(0,\,1), \\
\color{blue}{Y} &=& 3 \cdot \color{violet}{Z} + U_{\color{blue}{Y}}, \quad U_{\color{blue}{Y}} \sim \mathcal{N}(0,\,1).
\end{eqnarray*}

Dabei steht $\mathcal{G}(1,\,10)$ für eine *Gleichverteilung* auf den Bereich von $1$ bis $10$ und $\mathcal{N}(0,\,1)$ für eine *Normalverteilung* mit den Parametern $\mu=0$ und $\sigma=1$, also eine Standardnormalverteilung. Die konkreten Funktionen und Parameter sind hier willkürlich gewählt.

Einsetzen von $f_{\color{violet}{Z}}$ in $f_{\color{blue}{Y}}$ ergibt 
$\color{blue}{Y} = 3 \cdot (5 \cdot \color{green}{X} +  U_{\color{violet}{Z}}) + U_{\color{blue}{Y}}=15 \cdot \color{green}{X} + 5 \cdot U_{\color{violet}{Z}} + U_{\color{blue}{Y}}.$

Für $n=100$ simulierten Beobachtungen lautet der dazugehörige `R`-Code:

```{r RSim, eval = FALSE}
## Vorbereitungen 
library(mosaic) # Paket laden
set.seed(1896) # Zufallszahlengenerator setzen (für Reproduzierbarkeit)

## Funktionen
U_X <- function(n = 1) runif(n, min = 1, max = 10)
f_Z <- function(x) 5 * x + rnorm(length(x))
f_Y <- function(z) 3 * z + rnorm(length(z))

## Datentabelle
n <- 100 # Anzahl Beobachtungen
SimData <- tibble(x = U_X(n)) %>%
  mutate(z = f_Z(x)) %>%
  mutate(y = f_Y(z)
```

## Lineare Regression, Versuch 1

Natürlich wissen Sie in den meisten Anwendungsfällen nicht, welches System an Gleichungen Ihren Daten zugrundeliegen. 
Stattdessen sammeln Sie Daten und untersuchen dann die Zusammenhänge, um Rückschlüsse über das zugrundeliegende System zu schließen.
Ein Verfahren, um Zusammenhänge zwischen Variablen $\color{green}{X}$ und $\color{blue}{Y}$ anhand von beobachteten Daten zu schätzen, ist die **Lineare Regression**.

***

*Anmerkung*: Siehe hierzu z. B. "Maschinelles Lernen" aus dem KI-Campus Kurs [The Elements of AI](https://ki-campus.org/courses/elementsofai).

***

Dabei wird angenommen, dass der Zusammenhang zwischen der zu erklärenden Variable $\color{blue}{Y}$ und den weiteren Variablen im Modell linear ist, d. h., es reicht *nur* die jeweiligen Steigungen zu schätzen, um den Zusammenhang zu beschreiben. So sieht es aus, wenn wir in unseren simulierten Daten den Zusammenhang zwischen Lernen und Verstehen berechnen:

```{r streu, out.width='80%', fig.align='center', echo = FALSE}
gf_point(y ~ x, data = SimData) %>% # Streudiagramm
  gf_lm() %>% # Regressionsgerade
  gf_labs(x = "x: Lernen", y = "y: Verstehen") # Achsenbeschriftung 
```

In `R` kann eine lineare Regression über die Funktion `lm()` berechnet werden.

Ohne den Mediator <violet> Wissen </violet> ergibt sich folgendes Modell:

```{r lmoz}
# Regression Rechnen
ModellA <- lm(y ~ x, data = SimData)
# Ergebnis
ModellA
```

D. h.:

$$\widehat{\color{blue}{\text{Verstehen}}} = `r round(coef(ModellA)[1],2)` + `r round(coef(ModellA)[2],2)` \times \color{green}{\text{Lernen}}$$

Gemäß dieses Modells liegt der (totale) kausale Effekt von <green>Lernen</green> auf <blue>Verstehen</blue> bei $`r round(coef(ModellA)[2],2)`$: Wird <green> Lernen</green> um eine Einheit erhöht, erhöht sich der Mittelwert von <blue> Verstehen </blue> um $`r round(coef(ModellA)[2],2)`$ Einheiten.

Das deckt sich mir den Ergebnissen unserer simulierten Intervention: Während die Werte für $\color{blue}{Y}$ bei $do(\color{green}{X}=1)$ um die $\color{blue}{15}$ schwankten, lagen sie bei $do(\color{green}{X}=10)$ um die $\color{blue}{150}$. Die Ergebnisse der linearen Regression entsprechen tatsächlich dem kausalen Effekt von Interesse.


***

*Anmerkung*: Der Fokus dieses Kurses liegt auf der Identifizierung von kausalen Effekten, nicht auf Schätzverfahren oder statistischer Inferenz. 
Wenn Sie damit vertraut sind, können Sie über `summary()` auch die *übliche* Regressionstabelle inkl. Standardfehler, p-Werten usw. erhalten:

```{r summary, exercise = TRUE}
# Regression Rechnen
ModellA <- lm(y ~ x, data = SimData)
# Ergebnis
summary(ModellA)
```

***

## Lineare Regression, Versuch 2

Aber was passiert, wenn der Mediator <violet> Wissen</violet>, $\color{violet}{Z}$, mit in das Modell aufgenommen wird?
Jetzt ändert sich das Ergebnis der linearen Regression:

```{r lmmz}
# Regression Rechnen
ModellB <- lm(y ~ x + z, data = SimData)
# Ergebnis
ModellB
```

D. h.:

$$\widehat{\color{blue}{\text{Verstehen}}} = `r round(coef(ModellB)[1],2)` + `r round(coef(ModellB)[2],2)` \times \color{green}{\text{Lernen}} + `r round(coef(ModellB)[3],2)` \times \color{violet}{\text{Wissen}}$$
Wenn <violet>Wissen</violet> Teil des Modell ist, wir also das <violet>Wissen</violet> berücksichtigen, um den kausalen Effekt von <green>Lernen</green> auf <blue>Verstehen</blue> zu bestimmen, dann sagt unser Modell jetzt: Wird <green> Lernen</green> um eine Einheit erhöht, erhöht sich der Mittelwert von <blue> Verstehen </blue> um $`r round(coef(ModellB)[2],2)`$ Einheiten &ndash; ein viel kleinerer Wert als ohne die Berücksichtigung ($`r round(coef(ModellA)[2],2)`$).

```{r adjustierung, echo=FALSE}
question("Welcher Wert beschreibt den (totalen) kausalen Effekt von Lernen (`x`) auf Verstehen (`y`) richtig? Also: Um wie viel Einheiten wird sich der Wert von Verstehen im Mittelwert ändern, wenn eine Einheit mehr gelernt wird?",
         answer("Der Wert aus dem Modell ohne Wissen (`ModellA`), d. h. $14.86$.", correct = TRUE, message = "Wie wir in der simulierten Intervention beobachtet hatten, ist dies der richtige Wert. Das Modell, das zusätzlich den Mediator enthält, berücksichtigt diesen Wert und unterbricht damit die kausale Kette von $X$ nach $Y$."),
         answer("Der Wert aus dem Modell mit Wissen (`ModellB`), d. h. $0.86$."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```


***

*Anmerkung*: Die geschätzten Werte in der Regression entprechen aufgrund von zufälligen Rauschen nicht den wahren Werten die wir für die Simulation verwendet haben.

***

## Zusammenfassung

:::{.box}
Um den (totalen) kausalen Effekt von $X$ auf $Y$ in einer Kette $$X \rightarrow Z \rightarrow Y$$ zu bestimmen, sollte ein Mediator $Z$ **nicht** berücksichtigt werden. Bei fixiertem $Z$ (z.B., wenn die Variable in einer Regression aufgenommen wird) wird der kausale Zusammenhang zwischen $X$ und $Y$ unterbrochen.
::: 

<a href="https://github.com/luebby/WWWEKI?tab=readme-ov-file#modul%C3%BCbersicht" class="btn btn-primary">Zur Modulübersicht (auf GitHub)</a>

## Hinweis

<red> **Dieser Kurs ist aktuell noch in der Entwicklung!** </red>

Bitte melden Sie Fehler, Unklarheiten und Verbesserungsvorschläge [hier](https://github.com/luebby/WWWEKI/issues).

Das Vorhaben *Was, wie, warum? Einstiegskurs Kausale Inferenz (WWWEKI)* wird mit Mitteln des Bundesministeriums für Bildung und Forschung unter dem Förderkennzeichen 16DHBQP040 gefördert.


![](images/csm_Logo-BMBF.jpg)


